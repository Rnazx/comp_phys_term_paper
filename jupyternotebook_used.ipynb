{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_snap_06 = \"/mnt/data1/sandeep/New_Gadget2_run/200Mpc_256/snapdir_seed_1690811/snap_06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import astropy.units as u\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Gadget2_snapshot_hdr:\n",
    "\n",
    "    def __init__(self, filename, DataFrame=False):\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            inp_file = filename\n",
    "        else:\n",
    "            print \"file not found:\"\n",
    "            sys.exit()\n",
    "        self.filename = filename   # keepig filename as self variable \n",
    "        self.Data_frame=DataFrame\n",
    "        f = open(inp_file,'rb')    # rb is for read binary\n",
    "        blocksize = np.fromfile(f,dtype=np.int32,count=1)\n",
    "        if blocksize[0]!=256:\n",
    "            raise ValueError(\"incorrect file format encountered when reading header of\")\n",
    "\n",
    "\t#==== Gadget2 struct_io_header =====\n",
    "\t# number of particles of each type in this file \n",
    "        self.npart = np.fromfile(f,dtype=np.int32,count=6)\n",
    "\n",
    "\t# mass of particles of each type. If 0, then the masses are explicitly\n",
    "\t# stored in the mass-block of the snapshot file, otherwise they are omitted \n",
    "        self.massarr   = np.fromfile(f,dtype=np.float64,count=6)\n",
    "\n",
    "\t# time of snapshot file \n",
    "        self.time      = (np.fromfile(f,dtype=np.float64,count=1))[0]\n",
    "\n",
    "\t# redshift of snapshot file \n",
    "        self.redshift  = (np.fromfile(f,dtype=np.float64,count=1))[0]\n",
    "\n",
    "\t# flags whether the simulation was including star formation \n",
    "        self.flag_sfr  = (np.fromfile(f,dtype=np.int32,count=1))[0]\n",
    "\n",
    "\t# flags whether feedback was included (obsolete) \n",
    "        self.flag_feedback = (np.fromfile(f,dtype=np.int32,count=1))[0]\n",
    "\n",
    "\t# total number of particles of each type in this snapshot. This can be\n",
    "\t# different from npart if one is dealing with a multi-file snapshot. \n",
    "        self.npartTotal    = np.fromfile(f,dtype=np.uint32,count=6)\n",
    "\n",
    "\t# flags whether cooling was included  */\n",
    "        self.flag_cooling  = (np.fromfile(f,dtype=np.int32,count=1))[0]\n",
    "\n",
    "\t# number of files in multi-file snapshot \n",
    "        self.num_files     = (np.fromfile(f,dtype=np.int32,count=1))[0]\n",
    "\n",
    "\t# box-size of simulation in case periodic boundaries were used \n",
    "        self.BoxSize       = (np.fromfile(f,dtype=np.float64,count=1))[0]\n",
    "\n",
    "\t# matter density in units of critical density \n",
    "        self.Omega0        = (np.fromfile(f,dtype=np.float64,count=1))[0]\n",
    "\n",
    "\t# cosmological constant parameter \n",
    "        self.OmegaLambda   = (np.fromfile(f,dtype=np.float64,count=1))[0]\n",
    "\n",
    "\t# Hubble parameter in units of 100 km/sec/Mpc \n",
    "        self.HubbleParam   = (np.fromfile(f,dtype=np.float64,count=1))[0]\n",
    "\n",
    "\t# flags whether the file contains formation times of star particles \n",
    "        self.flag_stellarage = (np.fromfile(f,dtype=np.float32,count=1))[0]\n",
    "\n",
    "\t# flags whether the file contains metallicity values for gas and star particles \n",
    "        self.flag_metals =  (np.fromfile(f,dtype=np.float32,count=1))[0]\n",
    "\n",
    "     \t# High word of the total number of particles of each type \n",
    "        self.npartTotalHighWord = np.fromfile(f,dtype=np.uint32,count=6)\n",
    "\n",
    "        # flags that IC-file contains entropy instead of u \n",
    "        self.flag_entropy_instead_u = (np.fromfile(f,dtype=np.float32,count=1))[0]\n",
    "\n",
    "        # fills to 256 Bytes \n",
    "        self.unused = np.fromfile(f,dtype=np.byte, count=60)\n",
    "        \n",
    "        blk_check = np.fromfile(f,dtype=np.int32,count=1)\n",
    "        if blocksize[0]!=blk_check[0]:\n",
    "            raise ValueError(\"I/O:ERRORBLOCKS NOT MATCHING\")\n",
    "        del blocksize, blk_check \n",
    "        f.close()\n",
    "        \n",
    "   #---------------------------------------------------------------------------------\n",
    "\n",
    "    def read_gadget_header(self):\n",
    "        \n",
    "\t\"\"\"\n",
    "\tSimply prints out the header of the file\n",
    "\t\"\"\" \n",
    "\n",
    "        print 'npar=',self.npart\n",
    "        print 'nall=',self.npartTotal\n",
    "        print 'a=',self.time\n",
    "        print 'z=',self.redshift\n",
    "        print 'masses=',self.massarr*1e10,'Msun/h'\n",
    "        print 'boxsize=',self.BoxSize,'kpc/h'\n",
    "        print 'filenum=',self.num_files\n",
    "        print 'cooling=',self.flag_cooling\n",
    "        print 'Omega_m,Omega_l=',self.Omega0,self.OmegaLambda\n",
    "        print 'h=',self.HubbleParam,'\\n'\n",
    "        print 'H0=', self.HubbleParam*100.* u.km*u.s**(-1)*u.Mpc**(-1)\n",
    "\n",
    "        rhocrit=2.77536627e11 #h**2 M_sun/Mpc**3\n",
    "        rhocrit=rhocrit/1e9 #h**2M_sun/kpc**3\n",
    "        \n",
    "        Omega_CDM=self.npartTotal[1]*self.massarr[1]*1e10/(self.BoxSize**3*rhocrit)\n",
    "        print 'DM mass=%.5e  Omega_DM = %.5f'\\\n",
    "          %(self.massarr[1]*1e10, Omega_CDM)\n",
    "\n",
    "    #------------- Read Particle Positions in comoving units kpc h^-1 ------------------\n",
    "    \n",
    "    def read_Pos(self, Double=False):\n",
    "        \n",
    "\t\"\"\"\n",
    "\tParam\n",
    "\tDouble: If True then positions are written in \n",
    "\t\tdouble else they are written in \n",
    "\t\n",
    "\treturns\n",
    "\tIf Data_frame is flase then returns the numpy \n",
    "\tarray of shape (3, Npart) else Panda's data frame\n",
    "\tof the same shape.  \n",
    "\t\"\"\"\n",
    "\n",
    "        with open(self.filename,'rb') as f:   # rb is for read binary\n",
    "                offset = 4+256+4\n",
    "\n",
    "                f.seek(offset, os.SEEK_CUR) # https://www.geeksforgeeks.org/python-seek-function/(???????)\n",
    "                blocksize = np.fromfile(f,dtype=np.int32,count=1) \n",
    "                #https://numpy.org/doc/stable/reference/generated/numpy.fromfile.html\n",
    "                \n",
    "                if not Double:\n",
    "                        dt = np.dtype((np.float32,3))  # Positions are in float not double\n",
    "                else:     \n",
    "                        dt = np.dtype((np.float64,3))  # Positions are in float not double\n",
    "\n",
    "                Pos = np.fromfile(f,dtype=dt,count=self.npart[1]) # https://numpy.org/doc/stable/reference/arrays.dtypes.html\n",
    "                blk_check = np.fromfile(f,dtype=np.int32,count=1)\n",
    "\n",
    "                if blocksize[0]!=blk_check[0]:\n",
    "                        raise ValueError(\"I/O:ERRORBLOCKS NOT MATCHING\")\n",
    "                \n",
    "                del blk_check, blocksize\n",
    " \n",
    "        \n",
    "        if self.Data_frame == True:\n",
    "            df = pd.DataFrame(Pos)\n",
    "            return df\n",
    "        else:\n",
    "            return Pos\n",
    "\n",
    "    #-------- Read Particle velocities in Gadget internal units as km s^-1 ---------\n",
    "\n",
    "    def read_Vel(self):\n",
    "    \n",
    "\t\"\"\"\n",
    "\treturns\n",
    "\tIf Data_frame is flase then returns the numpy \n",
    "\tarray of shape (3, Npart) else Panda's data frame\n",
    "\tof the same shape.  \n",
    "\t\"\"\"\n",
    "       \n",
    "        f = open(self.filename,'rb')  # rb is for read binary\n",
    "        \n",
    "        # Calculate the offset from the beginning of the \n",
    "\t# file: 4 bytes (endianness) + 256 bytes (header) + 8 bytes (void)\n",
    "\n",
    "        offset = 4+256+8\n",
    "        \n",
    "        #Skip all the particle Position (four bytes per position * three coordinates* number of particles)\n",
    "        offset += 4 * 3 * self.npart[1]\n",
    "        f.seek(offset+4, os.SEEK_CUR)\n",
    "        \n",
    "        blocksize = np.fromfile(f,dtype=np.int32,count=1)\n",
    "        dt = np.dtype((np.float32,3))  # velocities are in float not double\n",
    "        Vel = np.fromfile(f,dtype=dt,count=self.npart[1])\n",
    "\n",
    "        blk_check = np.fromfile(f,dtype=np.int32,count=1)\n",
    "        \n",
    "        if blocksize[0]!=blk_check[0]:\n",
    "            raise ValueError(\"I/O:ERRORBLOCKS NOT MATCHING\")\n",
    "                    \n",
    "        del blk_check, blocksize\n",
    "        f.close()    \n",
    "        \n",
    "        if self.Data_frame == True:\n",
    "            df = pd.DataFrame(Vel)\n",
    "            return df\n",
    "        else:\n",
    "            return Vel\n",
    "        \n",
    "\n",
    "    #----------------- Read Particle ID --------------------------\n",
    "\n",
    "    def read_ID(self):\n",
    "    \n",
    "        f = open(self.filename,'rb')    # rb is for read binary\n",
    "        \n",
    "        # Calculate the offset from the beginning of the \n",
    "\t# file: 4 bytes (endianness) + 256 bytes (header) + 8 bytes (void)\n",
    "        \n",
    "        offset = 4+256+8\n",
    "        #Skip all the particle Position\n",
    "        offset += 4 * 3 * self.npart[1]\n",
    "        offset+=8\n",
    "        #Skip all the particle velocities\n",
    "        offset += 4 * 3 * self.npart[1]\n",
    "\n",
    "        f.seek(offset+4, os.SEEK_CUR)\n",
    "        \n",
    "        blocksize = np.fromfile(f,dtype=np.int32,count=1)\n",
    "\n",
    "        Part_ID = np.fromfile(f,dtype=np.uint32, count=self.npart[1])\n",
    "        blk_check = np.fromfile(f,dtype=np.int32,count=1)\n",
    "        \n",
    "        if blocksize[0]!=blk_check[0]:\n",
    "            raise ValueError(\"I/O:ERRORBLOCKS NOT MATCHING\")\n",
    "            \n",
    "        del blk_check, blocksize\n",
    "        f.close()    \n",
    "\n",
    "        return Part_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.0\n",
      "npar= [       0 33979285        0        0        0        0]\n",
      "nall= [         0 1073741824          0          0          0          0]\n",
      "a= 1.0\n",
      "z= 4.4408920985e-16\n",
      "masses= [  0.00000000e+00   1.06549701e+10   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00] Msun/h\n",
      "boxsize= 512000.0 kpc/h\n",
      "filenum= 32\n",
      "cooling= 0\n",
      "Omega_m,Omega_l= 0.307115 0.692885\n",
      "h= 0.6777 \n",
      "\n",
      "H0= 67.77 km / (Mpc s)\n",
      "DM mass=1.06550e+10  Omega_DM = 0.30713\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(1, '/mnt/home1/sandeep/workspace/Simulations_workspace/python_routines/Gadget2_routines/')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "snapID = np.int32(22)\n",
    "nfiles = np.int32(32)\n",
    "dir_name= (\"/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/\")\n",
    "\n",
    "#/mnt/data1/sandeep/New_Gadget2_run/200Mpc_256/snapdir_seed_1690811/snap_06\n",
    "print dir_name \n",
    "if nfiles<=1:\n",
    "    inp_file = dir_name + \"snapshot_%03d\"%(snapID)\n",
    "else:\n",
    "    inp_file = dir_name + \"snapshot_%03d.%d\"%(snapID, 0)\n",
    "    print(inp_file)\n",
    "\n",
    "snapshot = Gadget2_snapshot_hdr(inp_file, DataFrame=True)\n",
    "snapshot_header =  snapshot.read_gadget_header()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.0\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.1\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.2\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.3\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.4\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.5\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.6\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.7\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.8\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.9\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.10\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.11\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.12\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.13\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.14\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.15\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.16\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.17\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.18\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.19\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.20\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.21\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.22\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.23\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.24\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.25\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.26\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.27\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.28\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.29\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.30\n",
      "/mnt/data1/sandeep/Kalinga_run_Analysis/512Mpc_1024/kalinga_snapdir_seed_1690811/snapshot_022.31\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from astropy.io import ascii\n",
    "\n",
    "    \n",
    "\n",
    "scale_fac = 1./(1.+snapshot.redshift)\n",
    "unit_kpc_Mpc = np.float32(0.001)\n",
    "vel_conv_factor = np.float32(1./np.sqrt(scale_fac))\n",
    "\n",
    "posx = np.zeros(1, dtype=np.float64)\n",
    "posy = np.zeros(1, dtype=np.float64)\n",
    "posz = np.zeros(1, dtype=np.float64)\n",
    "\n",
    "velx = np.zeros(1, dtype=np.float64)\n",
    "vely = np.zeros(1, dtype=np.float64)\n",
    "velz = np.zeros(1, dtype=np.float64)\n",
    "\n",
    "for i in xrange(nfiles):\n",
    "\n",
    "    if nfiles<=1:\n",
    "        inp_file = dir_name + \"snapshot_%03d\"%(snapID)\n",
    "    else:\n",
    "        inp_file = dir_name + \"snapshot_%03d.%d\"%(snapID, i)\n",
    "    print(inp_file)\n",
    "\n",
    "    snapshot = Gadget2_snapshot_hdr(inp_file, DataFrame=False)\n",
    "    Pos  = snapshot.read_Pos() # is u.kpc*snapshot.HubbleParam**(-1)\n",
    "\n",
    "    Pos[:,0] = np.float64(Pos[:,0]*unit_kpc_Mpc)\n",
    "    Pos[:,1] = np.float64(Pos[:,1]*unit_kpc_Mpc)\n",
    "    Pos[:,2] = np.float64(Pos[:,2]*unit_kpc_Mpc)\n",
    "\n",
    "    posx = np.concatenate((posx, Pos[:,0]))\n",
    "    posy = np.concatenate((posy, Pos[:,1]))\n",
    "    posz = np.concatenate((posz, Pos[:,2]))\n",
    "\n",
    "\n",
    "    Vel  = snapshot.read_Vel() # to convert the Gadget velocity to comoving velocity\n",
    "    Vel[:,0] *= np.float64(vel_conv_factor)\n",
    "    Vel[:,1] *= np.float64(vel_conv_factor)\n",
    "    Vel[:,2] *= np.float64(vel_conv_factor)\n",
    "\n",
    "    velx = np.concatenate((velx, Vel[:,0]))        \n",
    "    vely = np.concatenate((vely, Vel[:,1]))        \n",
    "    velz = np.concatenate((velz, Vel[:,2]))        \n",
    "    del Pos, Vel \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################functions to find ngp and cic####################################\n",
    "\n",
    "def ngp(ngrid, slice_width, nbox, posi, offset):\n",
    "    posi[2] -= offset\n",
    "    new_pos = np.swapaxes(posi,0,1)\n",
    "    boxfac = np.float32(ngrid/nbox)\n",
    "    density = np.zeros((ngrid+1, ngrid+1, np.int32(boxfac*slice_width)+1)) #defining box of size ngrid\n",
    "    npart = len(new_pos) \n",
    "    new_pos = boxfac*new_pos\n",
    "    ints = np.floor(new_pos).astype(np.int32)  \n",
    "    print(ints.min(axis =0))\n",
    "    for i in xrange(len(ints)):\n",
    "        density[ints[i][0], ints[i][1], ints[i][2]] += 1\n",
    "                \n",
    "    return density\n",
    "\n",
    "\n",
    "def cic(ngrid,slice_width, nbox, posi, offset):\n",
    "    posi[2] -= offset\n",
    "    new_pos = np.swapaxes(posi,0,1)\n",
    "    boxfac = np.float32(ngrid/nbox)\n",
    "    density = np.zeros((ngrid+1, ngrid+1, np.int32(boxfac*slice_width)+1), dtype=np.float64) #defining box of size ngrid\n",
    "    \n",
    "    npart = len(new_pos) \n",
    "    new_pos = boxfac*new_pos\n",
    "    \n",
    "    frac = np.modf(new_pos)[0]\n",
    "    ints = np.floor(new_pos).astype(np.int32)\n",
    "                                                                                                                                                                                                                                                                                                                                                   \n",
    "    for i in xrange(-1,len(ints)-1):\n",
    "        for j in range(2):\n",
    "            if j == 1 : frac[i][0] = 1 - frac[i][0]\n",
    "            for k in range(2):\n",
    "                if k == 1 : frac[i][1] = 1 - frac[i][1]\n",
    "                for l in range(2):\n",
    "                    if l == 1 : frac[i][2] = 1 - frac[i][2]\n",
    "                    density[ints[i+j][0], ints[i+k][1], ints[i+l][2]] += (frac[i][0])*(frac[i][1])*(frac[i][2])\n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "#         density[ints[i+1][0], ints[i][1], ints[i][2]] += (frac[i][0])*(1 - frac[i][1])*(1 - frac[i][2])\n",
    "#         density[ints[i][0], ints[i+1][1], ints[i][2]] += (1 - frac[i][0])*(frac[i][1])*(1 - frac[i][2])\n",
    "#         density[ints[i][0], ints[i][1], ints[i+1][2]] += (1 - frac[i][0])*(1 - frac[i][1])*(frac[i][2])\n",
    "#         density[ints[i+1][0], ints[i+1][1], ints[i][2]] += (frac[i][0])*(frac[i][1])*(1 - frac[i][2])\n",
    "#         density[ints[i][0], ints[i+1][1], ints[i+1][2]] += (1 - frac[i][0])*(frac[i][1])*(frac[i][2])\n",
    "#         density[ints[i+1][0], ints[i][1], ints[i+1][2]] += (frac[i][0])*(1 - frac[i][1])*(frac[i][2])\n",
    "#         density[ints[i][0], ints[i][1], ints[i][2]] += (1 - frac[i][0])*(1 - frac[i][1])*(1 - frac[i][2])\n",
    "#         density[ints[i+1][0], ints[i+1][1], ints[i+1][2]] += (frac[i][0])*(frac[i][1])*(frac[i][2])\n",
    "        \n",
    "        \n",
    "\n",
    "    return density\n",
    "\n",
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Slice_width = np.float64(10)\n",
    "p = np.float64(0)\n",
    "index_z = (posz>=p + 0.0)*(posz<=p+Slice_width)\n",
    "positions = np.array([(posx[index_z])[1:], (posy[index_z])[1:], (posz[index_z])[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Slice_width = np.float64(10)\n",
    "for p in xrange(0,5,10):\n",
    "    p = np.float64(p)\n",
    "    index_z = (posz>=p + 0.0)*(posz<=p+Slice_width)\n",
    "    #print len(posx[index_z])\n",
    "\n",
    "    # my_table = [(posx[index_z])[1:], (posy[index_z])[1:], (posz[index_z])[1:],\n",
    "    #             (velx[index_z])[1:], (vely[index_z])[1:], (velz[index_z])[1:]\n",
    "    #            ]\n",
    "    positions = np.array([(posx[index_z])[1:], (posy[index_z])[1:], (posz[index_z])[1:]])\n",
    "    print(positions)\n",
    "\n",
    "    positions.min()\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from multiprocessing import Process\n",
    "    import matplotlib.cm as cm\n",
    "    from matplotlib.colors import LogNorm\n",
    "    import copy\n",
    "    #from de_funcs import ngp, cic\n",
    "\n",
    "\n",
    "    pos = copy.deepcopy(positions)  \n",
    "    pos1 = copy.deepcopy(positions) \n",
    "    print np.swapaxes(pos,0,1).min(axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ngrid = np.int32(1024)\n",
    "    nbox = np.float64(512)\n",
    "    lengrid = np.float64(nbox/ngrid)\n",
    "    slice_width = np.float64(10)\n",
    "\n",
    "    numgrid = lengrid*slice_width\n",
    "    print(numgrid)\n",
    "    npart = np.int32(len(pos[0]))\n",
    "\n",
    "    #finding ngp and cic 3-D arrays\n",
    "\n",
    "    den = ngp(ngrid,slice_width,nbox,pos,p)\n",
    "    denc = cic(ngrid,slice_width,nbox,pos1,p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #density check for cic\n",
    "    if int(denc.sum()) == npart : print('CIC is consistent with the mass density distribution')\n",
    "    print(denc.sum())\n",
    "    print(len(pos[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #density check for ngp\n",
    "    if int(den.sum()) == npart: print('NGP is consistent with the mass density distribution')\n",
    "    print(den.sum())\n",
    "    print(len(pos[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #slicing the density\n",
    "    grid_num = 0\n",
    "    print(den.shape)\n",
    "    den_2d = den[ :,:,grid_num]\n",
    "    denc_2d = denc[ :,:,grid_num]\n",
    "    for i in range(1,int(numgrid)+1):\n",
    "        den_2d += den[ :,:,grid_num + i]\n",
    "        denc_2d += denc[ :,:,grid_num + i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    from matplotlib.colors import LogNorm\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    min_den = den_2d.min()\n",
    "    max_den = den_2d.max()\n",
    "\n",
    "    min_denc = denc_2d.min()\n",
    "    max_denc = denc_2d.max()\n",
    "\n",
    "    print(min_den, max_den, min_denc, max_denc)\n",
    "\n",
    "    fig = plt.figure(figsize = (15,15))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    im = ax.imshow(denc_2d, \n",
    "            cmap=cm.afmhot, norm=LogNorm(vmin =0.8, vmax= 1000))\n",
    "    # ax1 = fig.add_subplot(1,2,2)\n",
    "    # im1 = ax1.imshow(denc_2d, \n",
    "    #         cmap=cm.afmhot, norm=LogNorm(vmin =0.8, vmax= 1000))\n",
    "    ax.savefig(str(p)+'cic_10Mpc_'+str(ngrid)+'g.eps', format='eps')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positions1 = np.array([(posx[:])[1:], (posy[:])[1:], (posz[:])[1:]])\n",
    "\n",
    "np.save('pos_512.npy', positions, fix_imports = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian kde kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20169011)\n",
      "(2, 20169011)\n",
      "<class 'scipy.stats.kde.gaussian_kde'>\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "print positions.shape\n",
    "X = copy.deepcopy(positions[0])\n",
    "Y = copy.deepcopy(positions[1])\n",
    "#print(X)\n",
    "\n",
    "from scipy.stats import gaussian_kde                                                                                                                                                                                                                                            \n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "xy = np.vstack([X,Y])\n",
    "print xy.shape\n",
    "z = gaussian_kde(xy)\n",
    "print type(gaussian_kde(xy))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(X, Y, c=z(xy), s=0.001)\n",
    "plt.show()\n",
    "\n",
    "# np.save('pos(w_1).npy', positions,fix_imports = True)\n",
    "\n",
    "Nx, Ny = 512, 512\n",
    "X, Y = np.meshgrid(np.arange(Nx), np.arange(Ny))\n",
    "print(X,Y)\n",
    "\n",
    "\n",
    "xy=np.vstack([X.flatten(),Y.flatten()])\n",
    "plt.scatter(X.flatten(), Y.flatten(),c=z(xy), s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary code for SPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def W( x, y, z, h ):\n",
    "\t\"\"\"\n",
    "    Gausssian Smoothing kernel (3D)\n",
    "\tx     is a vector/matrix of x positions\n",
    "\ty     is a vector/matrix of y positions\n",
    "\tz     is a vector/matrix of z positions\n",
    "\th     is the smoothing length\n",
    "\tw     is the evaluated smoothing function\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tr = np.sqrt(x**2 + y**2 + z**2)\n",
    "\t\n",
    "\tw = (1.0 / (h*np.sqrt(np.pi)))**3 * np.exp( -r**2 / h**2)\n",
    "\t\n",
    "\treturn w\n",
    "\t\n",
    "def getPairwiseSeparations( ri, rj ):\n",
    "\t\"\"\"\n",
    "\tGet pairwise desprations between 2 sets of coordinates\n",
    "\tri    is an M x 3 matrix of positions\n",
    "\trj    is an N x 3 matrix of positions\n",
    "\tdx, dy, dz   are M x N matrices of separations\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tM = ri.shape[0]\n",
    "\tN = rj.shape[0]\n",
    "\t\n",
    "\t# positions ri = (x,y,z)\n",
    "\trix = ri[:,0].reshape((M,1))\n",
    "\triy = ri[:,1].reshape((M,1))\n",
    "\triz = ri[:,2].reshape((M,1))\n",
    "\t\n",
    "\t# other set of points positions rj = (x,y,z)\n",
    "\trjx = rj[:,0].reshape((N,1))\n",
    "\trjy = rj[:,1].reshape((N,1))\n",
    "\trjz = rj[:,2].reshape((N,1))\n",
    "\t\n",
    "\t# matrices that store all pairwise particle separations: r_i - r_j\n",
    "\tdx = rix - rjx.T\n",
    "\tdy = riy - rjy.T\n",
    "\tdz = riz - rjz.T\n",
    "\t\n",
    "\treturn dx, dy, dz\n",
    "\t\n",
    "\n",
    "def getDensity( r, pos, m, h ):\n",
    "\t\"\"\"\n",
    "\tGet Density at sampling loctions from SPH particle distribution\n",
    "\tr     is an M x 3 matrix of sampling locations\n",
    "\tpos   is an N x 3 matrix of SPH particle positions\n",
    "\tm     is the particle mass\n",
    "\th     is the smoothing length\n",
    "\trho   is M x 1 vector of accelerations\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tM = r.shape[0]\n",
    "\t\n",
    "\tdx, dy, dz = getPairwiseSeparations( r, pos );\n",
    "\t\n",
    "\trho = np.sum( m * W(dx, dy, dz, h), 1 ).reshape((M,1))\n",
    "\t\n",
    "\treturn rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nx, Ny ,Nz= 512, 512 ,10\n",
    "X, Y, Z = np.meshgrid(np.arange(Nx), np.arange(Ny), np.arange(Nz))\n",
    "h = plt.contourf(getDensity(np.vstack([X,Y,Z]),np.vstack([positions[0],positions[1],positions[2]]),1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bf51d190d036b2eb75ef325439ffd1b7ae36f8ee5e305815eacd8423099ab81"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
